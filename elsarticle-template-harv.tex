%% 
%% Copyright 2007-2019 Elsevier Ltd
%% 
%% This file is part of the 'Elsarticle Bundle'.
%% ---------------------------------------------
%% 
%% It may be distributed under the conditions of the LaTeX Project Public
%% License, either version 1.2 of this license or (at your option) any
%% later version.  The latest version of this license is in
%%    http://www.latex-project.org/lppl.txt
%% and version 1.2 or later is part of all distributions of LaTeX
%% version 1999/12/01 or later.
%% 
%% The list of all files belonging to the 'Elsarticle Bundle' is
%% given in the file `manifest.txt'.
%% 
%% Template article for Elsevier's document class `elsarticle'
%% with harvard style bibliographic references

% \documentclass[preprint,12pt,authoryear]{elsarticle}

%% Use the option review to obtain double line spacing
\documentclass[authoryear,preprint,review,12pt]{elsarticle}

%% Use the options 1p,twocolumn; 3p; 3p,twocolumn; 5p; or 5p,twocolumn
%% for a journal layout:
%% \documentclass[final,1p,times,authoryear]{elsarticle}
%% \documentclass[final,1p,times,twocolumn,authoryear]{elsarticle}
%% \documentclass[final,3p,times,authoryear]{elsarticle}
%% \documentclass[final,3p,times,twocolumn,authoryear]{elsarticle}
%% \documentclass[final,5p,times,authoryear]{elsarticle}
%% \documentclass[final,5p,times,twocolumn,authoryear]{elsarticle}

%% For including figures, graphicx.sty has been loaded in
%% elsarticle.cls. If you prefer to use the old commands
%% please give \usepackage{epsfig}

%% The amssymb package provides various useful mathematical symbols
\usepackage{amssymb}
%% The amsthm package provides extended theorem environments
%% \usepackage{amsthm}
\usepackage{amsmath}

%% Giuliano: add support for tif images
\usepackage{epstopdf}
\epstopdfDeclareGraphicsRule{.tif}{png}{.png}{convert #1 \OutputFile}
\AppendGraphicsExtensions{.tif}

%% The lineno packages adds line numbers. Start line numbering with
%% \begin{linenumbers}, end it with \end{linenumbers}. Or switch it on
%% for the whole article with \linenumbers.
\usepackage{lineno}
\usepackage[dvipsnames]{xcolor}
\usepackage[capitalize]{cleveref}
\usepackage[inline]{enumitem}
\usepackage{siunitx}
\usepackage{multirow}
\usepackage{xspace} % required by the \gci command
\usepackage{xparse} % required by the section redefinition
\usepackage{ifthen} % required by the section redefinition
\usepackage{booktabs} % For formal tables


\newcommand{\note}[1]{\emph{\textcolor{red}{#1}}}
\newcommand{\update}[1]{\emph{\textcolor{blue}{#1}}}
\newcommand{\review}[1]{\emph{\textcolor{cyan}{#1}}}
\newcommand{\temp}[1]{\emph{\textcolor{gray}{#1}}}

\let\plainsection\section
\RenewDocumentCommand{\section}{s m o o}{
	\IfBooleanTF{#1}{
		% starred variant, unmodified
		\plainsection*{#2}
	}{
	    \IfNoValueTF{#3}{
	        % standard section
	        \plainsection{#2}
	    }{
	        \IfNoValueTF{#4}{
	            % only the assignee given
	            \plainsection{#2 (#3)}
	        }{
	        	\ifthenelse{
	        		\equal{#4}{todo}
	        	}{
	        		\plainsection{#2 (\textcolor{red}{#3 - TO DO})}
	        	}{}
	            \ifthenelse{
	            	\equal{#4}{wip}
	            }{
	            	\plainsection{#2 (\textcolor{red}{#3 - IN PROGRESS})}
	            }{}  
	        	\ifthenelse{
	        		\equal{#4}{update}
	        	}{
	        		\plainsection{#2 (\textcolor{blue}{#3 - UPDATE})}
	        	}{}
	        	\ifthenelse{
	        		\equal{#4}{review}
	        	}{
	        		\plainsection{#2 (\textcolor{cyan}{#3 - REVIEW})}
	        	}{}
	            \ifthenelse{
	            	\equal{#4}{done}
	            }{
	            	\plainsection{#2 (\textcolor{PineGreen}{#3 - READY})}
	            }{}
	        }
	    }
    }
}

\let\plainsubsection\subsection
\RenewDocumentCommand{\subsection}{s m o o}{
	\IfBooleanTF{#1}{
		% starred variant, unmodified
		\plainsubsection*{#2}
	}{
		\IfNoValueTF{#3}{
		    % standard section
		    \plainsubsection{#2}
		}{
		    \IfNoValueTF{#4}{
		        % only the assignee given
		        \plainsubsection{#2 (#3)}
		    }{
		    	\ifthenelse{
		    		\equal{#4}{todo}
		    	}{
		    		\plainsubsection{#2 (\textcolor{red}{#3 - TO DO})}
		    	}{}
		        \ifthenelse{
		        	\equal{#4}{wip}
		        }{
		        	\plainsubsection{#2 (\textcolor{red}{#3 - IN PROGRESS})}
		        }{}  
		    	\ifthenelse{
		    		\equal{#4}{update}
		    	}{
		    		\plainsubsection{#2 (\textcolor{blue}{#3 - UPDATE})}
		    	}{}
		     	\ifthenelse{
	        		\equal{#4}{review}
	        	}{
	        		\plainsubsection{#2 (\textcolor{cyan}{#3 - REVIEW})}
	        	}{}
		        \ifthenelse{
		        	\equal{#4}{done}
		        }{
		        	\plainsubsection{#2 (\textcolor{PineGreen}{#3 - READY})}
		        }{}
		    }
		}
	}
}

\newcommand{\gci}{\update{AgriMetSupport}\xspace}
% options are: Agriprog, WeatherProg-GCI, AgriSupport, AgriMetSupport, 

\journal{Computers and Electronics in Agriculture}

\bibliographystyle{model2-names}\biboptions{authoryear}

\begin{document}

\begin{frontmatter}

%% Title, authors and addresses

%% use the tnoteref command within \title for footnotes;
%% use the tnotetext command for theassociated footnote;
%% use the fnref command within \author or \address for footnotes;
%% use the fntext command for theassociated footnote;
%% use the corref command within \author for corresponding author footnotes;
%% use the cortext command for theassociated footnote;
%% use the ead command for the email address,
%% and the form \ead[url] for the home page:
%% \title{Title\tnoteref{label1}}
%% \tnotetext[label1]{}
%% \author{Name\corref{cor1}\fnref{label2}}
%% \ead{email address}
%% \ead[url]{home page}
%% \fntext[label2]{}
%% \cortext[cor1]{}
%% \address{Address\fnref{label3}}
%% \fntext[label3]{}

%\title{weatherprog N1 publishing quality-controlled data from heterogeneous stations}
%\title{A cyber-physical infrastructure for agricultural meteorology and planning}
%\title{A platform for agricultural meteorology management \note{and planning (need more in the text)}: AgriMetSupport }
%\title{Agricultural meteorology management \note{and planning (develop it in the text)}: the AgriMetSupport platform }
%\title{A fully integrated platform for agricultural meteorology management and planning: the AgriMetSupport at work \note{to create certified data with no gaps} }
%\title{ Qualified data production for agricultural meteorology management and planning\review{: A case study using the AgriMetSupport infrastructure} }
\title{ Qualified data production for agricultural meteorology management and planning: A case study using an interoperable cyber-physical system }

%% use optional labels to link authors explicitly to addresses:
%% \author[label1,label2]{}
%% \address[label1]{}
%% \address[label2]{}

%\author{}
\author[dia,crisp]{Giuliano Langella\corref{cor}}
\address[dia]{Department of Agriculture, University of Naples Federico II, Via Università 100, 80055 Portici, NA, Italy}
\address[crisp]{Interdepartmental Research Centre on Earth Critical Zone, University of Naples Federico II, Via Università 100, 80055 Portici, NA, Italy}
\cortext[cor]{Corresponding author}
\ead{glangella@unina.it}

%\author[dia]{Raffaele Martino}
%\author[deeit]{Raffaele Martino}
%\address[dia]{Department of Agriculture, University of Naples Federico II, Via Università 100, 80055 Portici, NA, Italy}

%\author[deeit]{Massimo Nicolazzo}
%\address[deeit]{Department of Electrical Engineering and Information Technology, University of Naples Federico II, Via Claudio 21, 80125 Naples, NA, Italy}

\date{July 2022}

\begin{abstract}
% See the following to write the abstract: https://www.scopus.com/record/display.uri?eid=2-s2.0-85020284965&origin=resultslist&sort=cp-f&src=s&st1=webgis&st2=dss&nlo=&nlr=&nls=&sid=05d242451f19678a21dc297f4479242b&sot=q&sdt=cl&cluster=scosubtype%2c%22ar%22%2ct&sl=30&s=TITLE-ABS-KEY-AUTH%28webgis+dss%29&relpos=3&citeCnt=4&searchTerm=

%[COPIED] The current agrometeorological monitoring of the Campania Region is both inadequate for its users and insufficient to support the simulation of pest risk models.
%This work describes a cyber-physical system which has been designed to overcome these limitations, with the objective of
%	\begin{enumerate*}
%		\item automate all the tasks involved in climatic data management, including also the intervention of the human expert when appropriate,
%		\item develop dependable pest risk models and provide the input data they need, and 
%		\item provide real-time agrometereological data presentation.
%	\end{enumerate*}
%	The system is built around an automatic climatic data management engine called WeatherProg, which manages data collection, quality control, data reconstruction, and digital maps production.
%	A proper climatic database has been developed to support the operations of WeatherProg, as well as a Web application for real-time publication of data handled by the software.
%	Pest risk models, fed by point measurements and the digital maps produced by WeatherProg, are going to be prototyped.
%	Furthermore, a new small measurement station has been prototyped, with the aim of being low-cost and easy to relocate, in order to support the characterisation and models parameterisation for different areas.
%	This paper illustrates the current status of the system and discusses future directions.

% Computers & Electronics in Agriculture: no longer than 400 words.
%Key Steps to Plan Writing an Abstract [A]
% 1. Introduction—what is the topic?
% 2. Statement of purpose?
% 3. Summarize why have other studies not tackled similar research questions?
% 4. How has the research question been tackled?
% 5. How was the research done?
% 6. What is the key impact of the research?
%
%The goal of writing an abstract is to communicate [B]:
% 1. What was done? 
% 2. Why was it done? 
% 3. How was it done? 
% 4. What was found? 
% 5. What is the significance of the findings?
%
% I follow the suggestion given in [B] to write the following abstract.
An interoperable cyber-physical system -- called AgriMetSupport -- was implemented to manage mainly weather stations, agrometeorological data and services that can be developed in cascade (e.g. models enabling territorial and integrated pest risk management).
Such a system could become crucial to support competent territorial bodies which are in charge of setting up and maintaining an agrometeorological network. 
This task is becoming increasingly difficult because it is required to deal with complex operations carried out using agrometeorological data such as data storage, quality check, missing data management, build continuous raster maps by means of geospatial modelling, data sharing with stakeholders and so forth.
In addition, competent territorial bodies should implement these actions by pursuing secondary objectives such as the adoption of standardized, scientifically-sound and perhaps shared procedures amongst federated territories.

%AgriMetSupport can support to carry out most of these tasks while fulfilling the requirements outlined.
AgriMetSupport is made by physical, software and modular components which are all specifically designed to build an operative cyber-physical system supporting competent territorial bodies in their management and planning tasks, but also any other stakeholder dealing with the production or the consuming of agrometeorological data or any kind of service based on these data.
The fundamental aim of the work proposed in this paper is to validate the production of qualified and certified data using well-tuned procedures available along with AgriMetSupport.
The main finding is that such a cyber-physical structure can be spread to federated territories or can be used as the centralised system to manage distinct monitoring networks as it can ease the management of agrometeorological networks by competent territorial bodies while leaving complex issues to researchers or domain experts.
\end{abstract}

\begin{keyword}
%% keywords here, in the form: keyword \sep keyword
agricultural meteorology \sep cyber-physical system \sep validation of quality control \sep gap-filling procedure \sep digital and precision agriculture
%% PACS codes here, in the form: \PACS code \sep code

%% MSC codes here, in the form: \MSC code \sep code
%% or \MSC[2008] code \sep code (2000 is the default)
\end{keyword}

% HIGHLIGHTS
% 1) territorial bodies need advanced approaches to manage agro-meteorological data
% 2) the proposed cyber-physical system is made by both physical objects and advanced logics
% 3) an advanced logic of qualified and certified data production is validated
% 4) the proposed system simplifies any step from point-based measurements to digital climatic grids
% 5) the proposed system is in production in Campania Region and can be applied and scaled elsewhere

\end{frontmatter}

%\tableofcontents

\linenumbers

%% main text
%\section{}\label{}
%\section{NOTES}
%\begin{itemize}
%    \item Fig. 1, 2: trovare PPTX e modificare (Giul)
%    \item §5 completare sezione (Giul)
%    \item §6.2: Fig.3: highlight networks + new figure (Raf)
%    \item App B1 può andare in §6 (Raf: IMHO, all appendices may be removed. B1 might be recovered in §6, and the others could be moved in their dedicated papers just in case we might reconsider them)
%\end{itemize}

%Deadline for submission: 31-Dec-2022

\section{Introduction}

%journal: Computers and Electronics in Agriculture
% https://www.journals.elsevier.com/computers-and-electronics-in-agriculture

% ==== Big Picture ====
%Include the big picture: The Earth Critical Zone requires that models such as SPA and pest models have quality checked data.
%\begin{itemize} 
%    \item Problem statement
%    \item Related work
%    \item Objectives
%\end{itemize}

% ==== Earth Critical Zone ====
%It is a living, breathing, constantly evolving boundary layer where rock, soil, water, air, and living organisms interact. These complex interactions regulate the natural habitat and determine the availability of life-sustaining resources, including our food production and water quality.
%The Critical Zone (CZ) is the support system for all terrestrial ecosystems, extending from unweathered rock to the top of any vegetation canopy. In the CZ, physical, biological, geological and hydrological processes interact at multiple temporal and spatial scales.
%Earth's critical zone is the “heterogeneous, near surface environment in which complex interactions involving rock, soil, water, air, and living organisms regulate the natural habitat and determine the availability of life-sustaining resources”
Climate controls the Earth's Critical Zone (ECZ) in combination with other physical, biological and geological processes.
The ECZ is a heterogeneous system extending from the top of the vegetation canopy to the bottom of unweathered rocks, regulates the availability of resources and modulates the production of ecosystem services such as the filtration and quality of water, and the production of food and fibre.

% ==== Agricultural Meteorology ====
% LINKS:
%   https://books.google.it/books?id=vdFBDwAAQBAJ&pg=PA22&lpg=PA22&dq=importance+of+agrometeo+measurements&source=bl&ots=CmcFAArYyq&sig=ACfU3U1TMqCpGqAv7VZjSz1M_IgPKv1--w&hl=it&sa=X&ved=2ahUKEwjPs_Tdg_vgAhXQ4KQKHYM3B4AQ6AEwAHoECAkQAQ#v=onepage&q=importance%20of%20agrometeo%20measurements&f=false
%   http://www.agrometeorology.org/files-folder/repository/gamp1.pdf
%   https://en.wikibooks.org/wiki/Introductory_Agrometeorology/Introduction
%   http://www.agrilearner.com/agrometeorology-needs-scope/
%   http://www.agriinfo.in/default.aspx?page=topic&superid=1&topicid=377

%Weather: Physical state of the atmosphere at a given place and given time. Eg. Cloudy day
%Climate: Long term regime of atmospheric variables of a given place or area. Eg. Cold season
%and considered as basic input or resources in agricultural planning, every plant process related with growth development and yield of a crop is affected by weather.

Weather and climate are the most important dynamic components of the ECZ determining the physical condition in which animals and plants are grown.
Weather is the physical state of the atmosphere at any spatiotemporal coordinate, while climate represents an aggregation of atmospheric variables mostly over time (e.g. seasonal extremes) but also in the spatial domain (e.g. regional extremes).
Agricultural meteorology is concerned with the monitoring of weather and the characterisation of the meteorological, hydrological and pedological factors that have a direct effect on agriculture and the production of crops and livestocks.
% http://www.agriinfo.in/default.aspx?page=topic&superid=1&topicid=377
Agricultural meteorology is deemed important considering the large amount of ground stations available worldwide to monitor the behaviour of weather elements, notwithstanding, for instance, the huge amounts of air-borne proxy products coming from massive satellite monitoring.
Indeed, amongst others, it helps: 
    \begin{enumerate*}
        \item understanding the realisation of several crop parameters such as the growing season and the harvesting time;  \citep{Hoogenboom:agrometeo-swat:2000,Chou2019,Madhukar2021,Richmond2022};
        \item managing crops by means of various farm operations such as fertilisers application and irrigation scheduling \citep{Cammarano2021,Chen2020};
        \item assessing the suitability of specific crops both in space for instance by means of agroclimatic zoning and in time in particular according to climate change \citep{Rokochynskiy2020,Jiang2020};
        \item crop and livestock monitoring and modelling \citep{Vogel2021,Zhang2022} \note{search at least 1 paper on livestock modeling};
        \item understanding the spatial distribution of soil types and soil properties since climate is one of the soil forming factors recognized in both CLORPT \citep{jenny:clorpt:1941} and SCORPAN \citep{McBratney:scorpan:2003} models;
        \item forecasting plant pests and diseases \note{search...}.
    \end{enumerate*}

There is an increasing demand for the production, in digital format, of weather and climatic data of good quality within the earth critical zone both 
    for practical applications (e.g. the need to know climatic patterns in a farm to improve the management)
    and
    for research and development, in particular to simulate the soil-plant-atmosphere system \citep{Hoogenboom:agrometeo-swat:2000,Jones:swat:2003,Seneviratne:swat:2010} % \citep{Langella:rainann:2010}
    and the risk of pests \citep{Orlandini:plasmopara:2008,Rossi:vitenet:2014}.
    % \citep{Terribile:dssvitis:2017}
The demand is particularly burdensome considering the requirement to handle climatic data both at finer temporal scale and in a continuous spatial domain.
It means that daily (e.g. in the soil hydrological modelling) or even hourly records (e.g. in the phytopathologic risk modelling) measured at point gauges sparsely located in a territory must be transformed in three dimensional climatic data cubes (Longitude, Latitude, Time) by means of statistically sound geospatial procedures.
% (there is a gap between the major of scientific modelling approaches that requires digital climate maps and the gauged measurements).
There exist few approaches implementing and deploying automatic spatial inference engines of this kind based on point agrometeorological data at the daily or even at the hourly time step.
One example working in USA using already checked daily data, is given by the expert-based model called PRISM developed by  \cite{Daly08_PRISM_USA}. %\note{(search for other REFs? may be sufficient!)}

% ==== Aim ====
%Support systems to agrometeorological practices and services comprise data (so quantification), research, training/education/extension and policy environments. Especially in industrialized countries mathematical models are increasingly used in operational agricultural meteorology, in conjunction with Geographic Information Systems (GISs) to provide inputs to Decision Support Systems (DSSs).
Especially in more developed countries, mathematical models are increasingly used in agriculture in conjunction with Geographic Information Systems (GISs), also via web in the form of WebGIS, to provide inputs to Decision Support Systems (DSSs), possibly via web in the form of Web Based geoSpatial Decision Support Systems (WB-SDSS).
Examples of WB-SDSS can be found 
for heavy metal pollution management in soils \citep{Wang:wbsdss:2005}, 
for livestock manure management \citep{Acutis:wbsdss:2014}, 
for locust prevention and control \citep{Yao:wbsdss:2017}, 
for optimized crop irrigation \citep{Giusti:wbsdss:2015}, 
for land management and soil conservation \citep{Terribile:soilconsweb:2015}, 
for early warning systems in areas of weather and climate \citep{Bopape_2019},
and so forth.
%\review{ include also examples of possibile similar GCIs such as \citep{Bopape_2019}...; hydrometeorological;  }

There exist a huge production of DSS tools on quite every issue related to the agricultural and forestry systems.
%\note{what is missing? a GCI on agrometerological data to facilitate the assembly of tools to support decision process in issues related to agriculture and forestry.  }
To authors' knowledge, there is a gap in literature concerning Geospatial Cyber-Infrastructures (GCIs) fully dedicated to agriculture meteorology, both to implement a stand-alone agrometeorological platform and to facilitate the assembly of tools to support the decision process in issues related to the earth critical zone with particular reference to agriculture and forestry. 
Results obtained on scopus.com (December 2022) reveals that 314 documents (papers and books excluding conferences) were published on cyber infrastructures applied in (agro-)meteorology, while none of them were relevant to the peculiar scope of our work.
% To authors' knowledge there is any work in literature dealing with GCI
% SCOPUS = "geospatial cyber infrastructure agrometeorology" ==> 0 results
% SCOPUS = "cyber infrastructure agrometeorology" ==> 0 results
% SCOPUS = "cyberinfrastructure meteorology" ==> 13 results, but not pertinent
% SCOPUS = "geospatial agrometeorology decision support" ==> 0 results
% SCOPUS,Dec-2022 = cyber AND infrastructure AND meteorology ==> 314 documents, see list of selected 25 documents in my private area on SCOPUS.

In this paper a strongly modular GCI, called AgriMetSupport
is proposed as a general technological framework being a WB-SDSS, that can be fully tailored to the specific needs of an existent agrometeorological network (e.g. those managed by local government agencies).
The proposed GCI is based on a software component, namely WeatherProg \citep{langella:weatherprog2014,langella:weatherprog2016}, which represents the main engine of the information technology system.
It has the potential of being the basic engine of several geospatial-based services in agriculture, in which both the weather and the climatic information is of paramount importance.
WeatherProg has the key advantage of implementing all the tasks from gathering the raw measurements coming from the agrometeorological sensors till the delivery of digital climatic maps at different time steps (e.g. hourly, daily, and so forth).

Together with the presentation of the general template WB-SDSS, the results of applying the AgriMetSupport GCI to a specific case study, that is in Campania Region (South of Italy), is shown with the specific focus of producing qualified and certified data.
The task consists in tuning a fully automatic or assisted procedure to quality check and gap-fill the measurements carried out at gauged points.
This is of particular relevance due to limitations and constraints (showed in \cref{sec:qcheck}) of the Campania Region agrometeorological network.

The work is presented following a hierarchical structure, starting from the most general to the more particular part.
In section \ref{sec:gci} the overall geospatial cyber-infrastructure (AgriMetSupport) implementing the decision support system is described.
In section \ref{sec:weatherprog} the core engine (WeatherProg) processing the agrometeorological data is shown with emphasis on the main modules and their role in the infrastructure.
It is emphasised the high flexibility of the whole platform and the high granularity of its components.
Section \ref{sec:qcheck} provide details about the data quality control and the infilling procedures, highlighting the operations required to produce data of good quality to be used in cascade in other 
applications.
The deployment of the AgriMetSupport GCI to a real case, namely in Campania Region (South of Italy), is presented in section \ref{sec:casestudy}.

\section{The AgriMetSupport cyber-physical infrastructure} \label{sec:gci}
%Central to the design of an effective automated data-processing system is the database. The telecommunications subsystem database must hold:
%(a) Bulletins of incoming messages;
%(b) Locally generated observations;
%(c) Products for national dissemination;
%(d) Bulletins of locally generated observations for transmission on the GTS.
%The applications subsystem database must hold:
%(a) Reports derived from decoded bulletins;
%(b) Fields derived from decoded bulletins;
%(c) Products prepared through the processing of reports and fields.
%If possible, the database residing in each computer should be controlled by the same database
%management system (DBMS), which should be relatively simple so as to minimize computing overheads and facil- itate the speed of response of the overall data-processing system.

AgriMetSupport is designed to be a comprehensive framework for agrometereological monitoring and data management.
It can be effectively used for a wide range of purposes, from simple agrometeorogical monitoring to digital climatic maps production and agricultual and forestry modeling and application, including predictive pest modeling.
Clearly, different real-world applications have different requirements, which can be all accomodated by AgriMetSupport thanks to its strongly modular architecture.
Components can be added or removed to a specific instance of AgriMetSupport effortlessly without affecting other parts of the system, as well as modules of the core engine, namely WeatherProg, which can be selectively enabled or disabled.
This way, end users (e.g. local government agencies) can actually derive their own tailored instances from the general model of AgriMetSupport.

The high-level architecture is illustrated in \cref{cyberPhysicalSystemFig}.
At the topmost level, AgriMetSupport is constituted by central components responsible for storage (postgreSQL with postGIS extension) and processing of data (e.g. WeatherProg).
Peripheral physical components are in charge of collecting data from the environment (i.e. sensors in the network) and peripheral software components deliver web services, such as web applications enabling the agrometeorological data consulting by end-users.

\begin{figure}
	\centering
	\includegraphics[angle=90,scale=.60]{figures/AgriMetSupport-fig.pdf}
	\caption{High level architecture of the AgriMetSupport cyber-physical system.
             The non-pysical parts of the whole system - including the Services block - is running at the Granatellum data center managed by CRISP and located at the Department of Agriculture,  University of Napoli Federico II.
 }
	\label{cyberPhysicalSystemFig}
\end{figure}

Peripheral components are the actual monitoring networks.
In fact, AgriMetSupport is capable of handling and integrating data coming from multiple heterogeneous networks of stations, possibly under the responsibility of different agencies working in the same territory.
Each network can include different kinds of station, and each network can submit data to AgriMetSupport in different formats, since the decoding module of WeatherProg can be configured to accommodate such differences.
The opportunity to integrate networks is of paramount importance to systematically optimise the joint management of public and/or private monitoring infrastructures with significant beneficial impact on cost saving and services enhancement.

%and reciprocal impact both on the different agencies sharing their data and on farmers and end users who can enjoy more accurate data and less uncertain services.

AgriMetSupport can be employed also in contexts where there is an insufficient monitoring network coverage of the territory.
In fact, it comes with its own monitoring network, characterised by smart stations which are particularly suitable for temporary deployments and for fine tuning the parameters of the various models included in the GCI \citep{Martino2019AFI}.
It must be stressed that the smart monitoring network is entirely optional, being a component like the others that can be simply removed if there is either an already excellent coverage of the territory or any micro-climatic monitoring is needed, therefore not preventing the use of AgriMetSupport in such scenarios. %\note{[add installation of low cost station by farmers]}

The AgriMetSupport infrastructure is based on the distinction amongst data, logic and visualisation tiers.
The data tier is made by different databases.
One database is usually maintained by local government agencies (e.g. by different Campania Region departments as it is shown in Section \ref{sec:casestudy}) which is in charge of retrieving raw records by the monitoring stations within its network.
A second database is the main AgriMetSupport WMO-compliant relational database (see the point database in \cref{cyberPhysicalSystemFig}) in which decoded raw measurements possibly coming from different networks are stored (e.g. from a local government agency and from smart stations).
This database supports all the WeatherProg modules execution and produces qualified data for agriculture meteorology management and planning.
%The first is a WMO-compliant relational data base used to store station measurements.
%The main central components are the WeatherProg core engine and the data bases. 
%Two main data bases are employed by AgriMetSupport.
A third database is optional and supports the management of smart stations data which are then ingested in the main point database.
The latter is a raster data base capable of handling the digital climatic maps which can be produced as spatio-temporal tiles by the WeatherProg engine.
An array database is used to stitch together the 2D maps or tiles calculated over time for the different agroclimatic variables to produce multi-dimensional arrays or data cubes, which can be  characterised by three (X, Y, Time) or four (X, Y, Time, Variable) dimensions.
Subsetting operations on these data cubes including trimming and slicing are embarrassingly parallel and scale up according to the number of available CPU cores.
This enables the production of performing dashboards in the presentation tier enabling the visualization opf climatic maps.
%The rasdaman DBMS \citep{baumann:rasdaman} has been chosen due to its representation of spatial data as datacubes, i.e. digital maps with more than two dimensions, where the third dimension is used to represent time.

The logic tier is centralised in AgriMetSupport and is made mostly by the WeatherProg engine (Section \ref{sec:weatherprog}) and by web servers capable of connecting AgriMetSupport to the external databases and to the smart stations.

Finally, the presentation tier includes various end-user interfaces providing a number of different services.
A data consulting web application publishes the agroclimatic data managed by the cyber-physical system to the general public.
It is in charge of providing a public or restricted access to the basic agrometeorological data (distinguishing between raw and quality controlled data) and to agrometeorological derived information, such as the consultation of bio-climatic indices rather than a pest risk service (the pest risk module within WeatherProg is under development).
In addition, more tailored services are provided through dedicated interfaces to automatically retrieve data. %(e.g. by means of a REST API).
There exists an Application Programming Interface (API) via web allowing machine-to-machine requests and enabling data retrieval in the context of Findability, Accessibility, Interoperability, and Reuse (FAIR) of digital assets.
Beyond a delivery service available for both private and public bodies, the web-API can be used to deploy dedicated web applications including tailored web mapping dashboards.
%A web-based interface is also available for officers in charge of the system to tune the operational parameters of WeatherProg's models. \note{really?}

\section{WeatherProg engine}\label{sec:weatherprog}
\subsection{Main modules}
WeatherProg \citep{langella:weatherprog2014} is a computer program to automatically manage agrometeorological data.
The first implementation was carried out as the baseline asynchronous engine for the raw weather records handling in the (LIFE08 ENV/IT/000408) SOILCONS-WEB project.
It was developed because the main input requirements of the different modelling chains embedded in the project DSS \citep{Terribile:soilconsweb:2015} were the availability of both (i) complete and homogeneous time series and (ii) spatially exhaustive digital maps of the key agrometeorological variables (e.g. temperature and precipitation).

After the end of the project, the program has been progressively modified and updated in order to accommodate the requirements of both local government agencies (such as Italian Regions) and farmers, also thanks to an innovative cyber-physical infrastructure which WeatherProg is embedded in (\cref{cyberPhysicalSystemFig}).
Indeed, WeatherProg can facilitate the work by a local administrative body which is in charge of managing and publishing agrometeorological data and of promoting measures for low pesticide-input pest management \citep{eu:dir128:2009}, for instance by producing bulletins based on bioclimatic indicators or on the results of pest simulation models.
WeatherProg can facilitate the work by a farmer too, since it supports for instance the implementation of an integrated pest management tool \citep{Terribile:dssvitis:2017} by configuring services in the context of Agriculture 4.0 and advanced IoT framework as depicted in \cref{cyberPhysicalSystemFig}.

Nowadays, WeatherProg is a geospatial engine that can be embedded in a web-based DSS dedicated to real-time and on-the-fly consulting of agrometeorological and derived variables in the form of spatial-point time series or in the form of geospatial maps.
Raw reports from a climatological network can be ingested and a different set of operations are performed ranging from the data checking to the delivery of gridded agrometerological variables.
Temperature, rainfall, relative humidity, solar radiation, atmospheric pressure and wind speed are the most commonly handled variables by the program at different time scales.

WeatherProg starts automatically at predefined time intervals when a new report from the monitoring network is available (which depends upon the station data logger query frequency), and carries out the following main operations:
\begin{enumerate}
    \item Complete data retrieval. The real-time report with measurements from all sensors and stations belonging to a monitoring network arrives to WeatherProg via either SFTP or HTTPS secure protocol.
    
    \item Data decoding and ingestion. After the report is decoded according to time scale and sensors, data are ingested in the the main AgriMetSupport WMO-compliant relational database.

    \item Quality control and flagging of data. Quality control of time series are performed to automatically demarcate good measurements from wrong and missing values, which are conveniently flagged for the subsequent and optional infilling procedure.
    An anomalous datum is detected thanks to a multilevel technology based on interlinked quality control types such as range, continuity, climatological, spatial, temporal and persistency.
    Certification of abnormality can be semi-automatic other than automatic.
    The semi-automatic procedure is the result of the combination of both the data-driven WeatherProg checking procedure and the knowledge-based human checking in order to finally assign the definitive flag (for details see Section \ref{sec:qcheck}).
    
    \item Data infilling. Anomalies and missing data are all flagged to be %interpolated by means of an automatic linear regression procedure.
    infilled in order to get complete and homogeneous time series.
    Different methods are available such as a deterministic approach based on moving average with a growing kernel, or a statistical method using a stepwise multilinear regression.
    It uses data from other stations and it performs an iterative optimization procedure to properly select the time series length and the regression covariates for infilling each single anomaly or gap.
    For more details see \cref{sec:infill}.
    
    \item Time scale aggregation. Variables are aggregated over time using different statistics (minimum, maximum, average, sum, most frequent, and so forth) computed on 10-minutes measurements after quality control and possibly infill procedures are fulfilled.
    %computed on the most fundamental units of measurements, that is 10-minutes records after quality control and possibly infill procedures are fulfilled.
    
    \item Point modeling. Complete and homogeneous time series about one or more variables at any monitoring station can be used to run a simulation model, such as crop growth, soil hydrological and pest risk models.
    WeatherProg already embeds bioclimatic indicators and can additionally include other models.
    
    \item Spatial interpolation and gridded data cubes. The spatial interpolation of sparse point data is performed considering the scale of the application that is requesting WeatherProg to produce the digital maps.
    Three-dimensional climatic data cubes (Easting, Northing and Time) are then formed enabling queries along any of the dimensions (such as slicing, dicing and trimming).
    According to the number of stations and to the density of the monitoring network, different models of spatial interpolation can be activated, such as the IDW (parameterized inverse distance weighted), kriging (ordinary or iterative regressive), and a PRISM-like approach \citep{Daly08_PRISM_USA}.
    \item Gridded modeling. Models and indicators available in the point modeling module can be run with grids of agrometeorological variables.
    In line of principle, gridded modeling can be implemented using two different approaches: a first approach in which the point model runs in time domain in a single point of the grid and then looping for all grid nodes.
    In a second approach, the code running the simulation model is written to accommodate array programming (at any time step all grid nodes are computed simultaneously) and moving forward in time domain step by step.
    In WeatherProg the former approach is already available while the latter approach is under development using GPU computing.
    
\end{enumerate}

\subsection{ Running schedule and module pipelines }
An AgriMetSupport instance can be easily created by instantiating the stack of Docker containers in charge of putting in place the three-tier GCI architecture composed by the databases, the WeatherProg engine and the web applications for data consulting and decision support.
Once the AgriMetSupport instance is created, the execution of different WeatherProg jobs must be arranged in a composite schedule to run %the procedure of handling agrometeorological data across 
different workflows.
In \cref{Fig:weatherprog:calls} a typical running schedule for air temperature is depicted, providing a reference to the specific case study of this work (i.e. Campania Region instance).
The schedule is composed of pipelines (each row in first column of Figure \ref{Fig:weatherprog:calls}) having different scopes which are orchestrated row-wise to manage all the basic and derived information required by AgriMetSupport.
The WeatherProg modules are the fundamental bricks used in the composition of schedules.
The key schedule parameters are the time scale of the target agrometeorological variable (e.g. 10 minutes), the pipeline execution frequency (e.g. every day) and the time domain extent (last 5 days) tackled by each pipeline run (first column of Figure \ref{Fig:weatherprog:calls}).
It means that the pipeline is executed every hour or every 3 days and works on a temporal window active only within the defined time extent, for instance from 6 days (-6d) to 5 days (-5d) before execution time.

This flexible configuration is further enhanced by the behaviour of the pipeline, since the schedule can have reanalysis and recursive pipelines in addition to a standard one (with a total of 10 rows and thus pipelines in Figure \ref{Fig:weatherprog:calls}).

A reanalysis pipeline builds a progressively updated version of quality controlled and infilled data (ReA in Figure \ref{Fig:weatherprog:calls}).
To cite an instance, the persistence control type strictly depends on reanalysis to write a meaningful flag, since only adjacent records in the time series that have already passed logic and continuity control types (that is only auxiliary data of good quality) can contribute. % to the quality control procedure.
As time passes by, more auxiliary measurements are available within the time window of WeatherProg modules in execution (both before and after the target time being checked). 
Until the last execution of the reanalysis, which happens when the moving window is out of range for a target time element, an updated version of both quality checked and infilled data is produced (data and flags are overwritten) and infilled data are never quality checked.
At this point, the time element, which is out of range of the moving window after the last reanalysis run, undergoes the recursion run.
A recursion pipeline (ReC in Figure \ref{Fig:weatherprog:calls}) is in charge of performing a quality check including infilled data and eventually performing a new infill procedure for each missing or anomalous singleton.
From now on, the time series is stable till the time element targeted by the last recursion run.

\begin{figure}
	\centering
	%\includegraphics[scale=.4]{figures/WeatherProg_fig.pdf}
	\includegraphics[scale=.4]{figures/WeatherProg-schedule-fig.pdf}
	\caption{WeatherProg job schedule for air temperature in a typical AgriMetSupport instance.
 Each row of the schedule is a pipeline and a total of 10 pipelines are showed.
 Standard, reanalysis and recursive pipelines are orchestrated to build homogeneous and complete agrometeorological (point and grid) database.}
	\label{Fig:weatherprog:calls}
\end{figure}

\section{Create qualified and certified data with no gaps}
%The deviation or switch was introduced in the 10-minutes pipeline tackling the daily run dedicated to the creation of no-gap and certified data, as depicted in \cref{Fig:weatherprog:calls} . \note{(MODIFY THE FIGURE TO ADD THE DEVIATION/SWITCH GRAPHICALLY))}.

\subsection{Quality control procedure} \label{sec:qcheck}
WeatherProg has a quality control module capable to managing data at 10 minutes, hourly and daily time scales.
The quality control can be of different types, such as range, continuity, persistence, climatological, spatial and temporal and not all quality control types are available neither at all time scales nor for all agrometeorological variables.
Possible flags for both any quality control type and the overall outcome are reported in \cref{tab:flagsSummary} with a short description for each flag.

When a new AgriMetSupport instance is created a new database is created too.
Agrometeorological 10-minutes data are inserted for the first time and they can span for a day, for a month, for a year or even for longer time periods.
This is an initial condition (see \textit{initialize} in \cref{Fig:weatherprog:calls}) in which all flags are switched to unchecked for all control types and to unprocessed for the overall outcome.
After the database is created with this first data ingest, WeatherProg is executed once carrying out a long-term run (LTR) on the whole available time series.
Taking as an example the schedule depicted in \cref{Fig:weatherprog:calls} for air temperature, the LTR executes only the range control on the whole time series at first step and then a new LTR is executed adding the other control types step by step.
In the last step, the LTR executes the control types all together completing the initialization step.
Once the LTR writes all quality control flags, the high gear condition is met and WeatherProg can run the pipelines as outlined in the schedule of \cref{Fig:weatherprog:calls}.

For simplicity, an overview of the quality control procedure (\cref{tab:qcheck_m10_airT}) is presented only at the 10 minutes time scale for air temperature both in this section and in section \ref{sec:QcheckValidation} where the quality control procedure will be validated.
There is an implementation logic based on 15 different combinations of four quality control types, namely range, continuity, persistence and spatial.
Each combination or row shown in \cref{tab:qcheck_m10_airT} can be reached only if all previous combinations are not satisfied.
The sequence of combinations on rows depends on the absolute and relative weight given to each control type.
Let's provide few examples for any given datum.
If the range control type returns a wrong flag it is unnecessary to check any other control type and the overall quality control procedure has an outcome flag equal to wrong (ID=3 in \cref{tab:qcheck_m10_airT}).
Further, if range is correct and continuity is wrong it is unnecessary to consider the flags for persistence and spatial control types and the overall quality control procedure has an outcome flag equal to wrong again (ID=8 in \cref{tab:qcheck_m10_airT}).
Conversely, if range is correct and continuity is dubious than the spatial flag is relevant to get an overall outcome correct (ID=9 in \cref{tab:qcheck_m10_airT}), wrong (ID=10 in \cref{tab:qcheck_m10_airT}) or even dubious (ID=11 in \cref{tab:qcheck_m10_airT}) according to the continuity status of other stations in the spatial neighbourhood of the station being processed.
In general, the implemented logic forces to reduce the probability of dubious flags since a dubious singleton is not discarded until either evidence or a human sets it as either correct or wrong.

%The description of flags for the outcome of the quality control procedure can be found in %\cref{tab:qcheckOutcomeFlagsSummary}.
%\note{I would fuse \cref{tab:flagsSummary} and \cref{tab:qcheckOutcomeFlagsSummary}}.

\begin{table}[]
    \begin{scriptsize}
    \centering
    \begin{tabular}{r r l p{7cm}}
    % \multicolumn{2}{c}{Blablabla} \\
    \hline
    Control element & Flag & Abbreviation & Description \\
    \hline
	Control types & UNCHECKED     & UC & The quality control type has not been applied yet. Either this measurement has not undergone quality control at all yet, or this type was disabled.\\
	& CORRECT       & C  & This measurement appears to be correct according to this quality control type. \\
	& DUBIOUS       & D  & The quality control type has completed, but it cannot decide neither for correctness nor for wrongness. \\
	& AUXMISSING    & AM & The quality control type cannot complete, due to the lack of required auxiliary data. \\
	& AUXUNRELIABLE & AU & The quality control type cannot complete, because the required auxiliary data are available but they have not passed the quality control procedure themselves yet. \\
	& WRONG         & W  & This measurement appears to be wrong according to this quality control type. \\
 
    \hline

	Control procedure & UNPROCESSED & UP & This measurement has not undergone quality control at all yet.\\
	& CORRECT     & C  & This measurement is deemed correct by the quality control procedure.\\
	& DUBIOUS     & D  & This measurement is suspicious, but the quality control procedure cannot decide neither for correctness nor for wrongness. A knowledge-based human checking is required. \\
	& UNDECIDED   & UD & The measurement has been subject to the quality control procedure, but there is not sufficient ground yet to decide either for correctness or for wrongness. Reanalysis runs may have the additional information required to solve the indecision.\\
	& WRONG       & W  & This measurement is deemed not correct by the quality control procedure.\\
    \hline    
    \end{tabular}
    \caption{Flags used in any quality control type (range, continuity, persistence, climatological, spatial, temporal) and possible outcome status of the overall quality control procedure.}
    \label{tab:flagsSummary}
    \end{scriptsize}
\end{table}

%\begin{table}[]
%    \begin{scriptsize}
%    \centering
%    \begin{tabular}{r l p{10cm}}
%    % \multicolumn{2}{c}{Blablabla} \\
%    \hline
%    Flag & Abbreviation & Description \\
%    \hline
%	UNPROCESSED & UP & This measurement has not undergone quality control at all yet.\\
%	CORRECT     & C  & This measurement is deemed correct by the quality control procedure.\\
%	DUBIOUS     & D  & This measurement is suspicious, but the quality control procedure cannot decide neither for correctness nor for wrongness. A knowledge-based human checking is required. \\
%	UNDECIDED   & UD & The measurement has been subject to the quality control procedure, but there is not sufficient ground yet to decide either for correctness or for wrongness. Reanalysis runs may have the additional information required to solve the indecision.\\
%	WRONG       & W  & This measurement is deemed not correct by the quality control procedure.\\
%   \hline
%    \end{tabular}
%    \caption{Possible outcome status of the quality control procedure.}
%    \label{tab:qcheckOutcomeFlagsSummary}
%    \end{scriptsize}
%\end{table}

\begin{table}[]
    \begin{scriptsize}
    \centering
    \begin{tabular}{l l l l l l l}
        \hline
        ID & Logical Operator & Range & Continuity & Persistence      & Spatial      & Outcome \\
        \hline
        1  & or               & UC    & UC         & UC               & UC           & UP \\
        2  & and              & C     & C          & C                & C            & C  \\
        3  & and              & W     & any        & any              & any          & W  \\
        4  & and              & C     & any        & W                & any          & W  \\
        5  & and              & C     & AU | AM    & AU | AM          & AU | AM      & UD \\
        6  & and              & C     & C          & C | AU | AM      & C | D        & C  \\
        7  & and              & C     & C          & C | AU | AM      & W            & D  \\
        8  & and              & C     & W          & any              & any          & W  \\
        %8  & and              & C     & W          & C | AU | AM      & D | W        & W  \\
        9  & and              & C     & D | W      & C | AU | AM      & C            & C  \\
        10 & and              & C     & D          & C | AU | AM      & W            & W  \\
        11 & and              & C     & D          & C | AU | AM      & D            & D  \\
        12 & and              & C     & W          & C | UC | AU | AM & UC | AU | AM & W  \\
        13 & and              & C     & D          & C | UC | AU | AM & UC | AU | AM & D  \\
        14 & and              & C     & C          & C | UC | AU | AM & UC | AU | AM & C  \\
        15 & or               & C     & AU | AM    & AU | AM          & AU | AM      & UD \\
        \hline
    \end{tabular}
    \end{scriptsize}
    \caption{Logic of the quality control procedure and outcomes implemented for the air temperature at the 10 minutes time scale.
    Flags are described in \cref{tab:flagsSummary} for both the quality control types and the final outcome status.
    More flags in the same cell are aggregated using the \textit{or} logical operator.
    For instance, persistence can be either AU or AM at ID=5. }
    \label{tab:qcheck_m10_airT}
\end{table}

\subsection{Gap-filling procedure} \label{sec:infill}
%Anomalies and missing data are all flagged to be %interpolated by means of an automatic linear regression procedure.
%infilled in order to get complete and homogeneous time series.
%Different methods are available such as a deterministic approach based on moving average with a growing kernel, or a statistical method approach using a stepwise multilinear regression using other stations after an iterative optimization step to properly select the time series length and the regression covariates.

WeatherProg has a module equipped with basic gap-filling methods which are dedicated to filling anomalies and data gaps.
For the purpose of this paper, the infilling method based on stepwise multiple linear regression (MLR) was used in order to allow for a validation analysis (see \cref{sec:QcheckValidation}).
The MLR methods starts with the selection of all gaps and anomalies for any station within a given  interval of time.
Then, for each datum to be infilled an optimisation block is executed iteratively on different time series lengths and on different numbers of regression covariates (i.e. the other stations used as independent variables in MLR).
Amongst the several regression models built for a missing or anomalous datum, the model characterised by the lowest RMSE is selected to predict the infilled value for that station in that date and time.
%The procedure is capable of dealing with all the anomalies and gaps while for any station found in a reference time interval.
Generally, the infill module avoids the selection of singletons that couldn't pass the quality check procedure. 
It means that data being potentially used as auxiliary but having flags different from CORRECT or DUBIOUS are discarded from covariates.

\section{Case study: AgriMetSupport at work in Campania Region} \label{sec:casestudy}

An AgriMetSupport instance was tailored to the requirements of the Campania Region.
%\review{ [...put here more text about the initialisation, also recalled in the end of Introduction.] }
This is of particular relevance considering huge limitations and constraints therein present.
Important limitations are the eco-environmental complexity of the study area, the scarcity of stations and the lack of long term time series for any station.
Other constraints are the urgent need for monitoring and sharing agrometeorological data in the regional territory %(highlight the important step forward thanks to our GCI)
and the urgent need for a system to assist the production of bulletins to help mitigate the effects of alien or autochthonous plant pests.
 
\subsection{Study area}\label{sec:StudyArea}
Located in southern Italy between \ang{13;45;}E, \ang{15;49;}E, \ang{39;59;}N and \ang{41;31;}N, Campania is the third most populated region of the Country, but due to its extension of about \SI{13600}{\metre\squared}, it is the most densely populated region of Italy.
Its inland is occupied by the Apennine Mountains, oriented roughly NW-SE, whereas the Sele and Campana plains border the coast.
The Sele plain is named after the river which traverse it, while the Campana plain is traversed by the Volturno river.
Nevertheless, the majority of the regional territory is hilly, for the 50\% of the territory, against the 35\% mountainous and the 15\% flat.
Consequently, the elevation ranges from \SIrange{0}{1904}{\metre} above mean sea level.

%     AGRONOMIC INFO e.g. the production of products of particular quality (DOP, IGP, DOC, DOCG; ...)
Since a large part of the territory is mountainous, the only agricultural zones exploited for cultivation are flat and partly hilly, even though a large pressure from urbanisation caused huge land take during the past decades, in particular  the coastal zones in Napoli, Salerno and Caserta, with municipalities that have amongst the highest population densities in Europe (i.e. the municipality of Portici in Naples).

Cultivated lands are favoured by the very fertile soils of volcanic origin and from the availability of water. 
Therefore, Campania is characterized by the high productivity of lands and by the high quality of agricultural products.
It holds a supremacy in Italy and abroad in several productions such as tomatos, potatoes, eggplants, peppers and peas, besides the fruit of fig trees, hazel trees, citrus fruit, apricots, plum, chestnut and cherries.
Very important is also the production of wine and oil.
The breeding is constituted in good part from cattle and buffalos, characteristic of the region is the production of the famous buffalo's mozzarella, exported worldwide.

%    AGRO-ECONOMY\dots e.g. the ecomic value of the regional production in the primary sector

\subsection{Monitoring networks}

Agrometeorological monitoring in the Campania Region is currently performed by a dedicated monitoring network, which is however insufficient to serve all the purposes of such monitoring, as discussed in more detail in \cref{RARStructure}.
This issue is being addressed by local government officials with a twofold strategy.
On one hand, data from the hydrogeological risk monitoring network is being integrated into the agroclimatic monitoring; details of the network and the challenges of the integration are provided in \cref{DPCNetwork}.
On the other hand, a number of low-cost stations from AgriMetSupport's own monitoring network have been deployed under a partnership with the Department of Agriculture of the University of Naples Federico II, to trial their usage for increasing the numerosity of the agrometereological network.
Since this deployment is experimental, it will not be discussed here in great detail, suffice it to say that AgriMetSupport allowed to integrate data from all these sources, and present them with an uniform interface.

\cref{tab:rarSummary} lists some statistics about the station networks, while \cref{fig:rarLocations} illustrates the deployment of the stations over the territory of the Campania region.

\subsubsection{Agrometeorological network\label{RARStructure}}

The WMO-compliant agrometeorological monitoring network of the Campania Region comprises, at the time of this writing, only 34 stations, and this number is already insufficient to properly capture the complexity of the environment of the Campania Region (\cref{sec:StudyArea}).
To make things worse, the stations vary in their instrumentation, hence there is not any station which is capable of measuring all the 11 fundamental climatic variables, although each climatic parameter is measured by at least one station.
The bare minimum instrumentation includes sensors for air temperature, rainfall and air humidity, and 10 stations of the network measure only these three parameters.
The least monitored variable is air pressure, with only 9 stations currently measuring it.
Agrometeorological stations are located from \SIrange{10}{770}{\metre} above mean sea level, highlighting scarce coverage mainly of the mountainous territory (which covers 35\% of the regional area).

\begin{table}[]
    \begin{scriptsize}
    \centering
    \begin{tabular}{c|c|c|c}
        \multirow{2}{*}{Network} & \multicolumn{2}{c|}{\footnotesize{Agroclimatic}} & \footnotesize{Hydrogeological} \\
        & \multicolumn{2}{c|}{\footnotesize{(\cref{RARStructure})}} & \footnotesize{(\cref{DPCNetwork})} \\
        Stations set & \textbf{\scriptsize{Active}} & \textbf{\scriptsize{All available}} & \textbf{\scriptsize{Integrated}} \\ 
        \hline
        Number of stations & 34 & 39 & 163\\
        \hline
        \multicolumn{4}{c}{General information} \\
        \hline
        Minimum elevation & \multicolumn{2}{c}{\SI{11}{\metre} a.m.s.l.} & \SI{1}{\metre} a.m.s.l. \\
        Maximum elevation & \multicolumn{2}{c}{\SI{769}{\metre} a.m.s.l.} & \SI{1169}{\metre} a.m.s.l.\\
        Measurements time scale & \multicolumn{2}{c}{\SI{10}{\minute}} & \SI{10}{\minute} \\
        \hline
        \multicolumn{4}{c}{Length of the time series available in AgriMetSupport} \\
        \hline
        $<$ 1 year & 0 & 2 & 0 \\
        1 year & 0 & 3 & 163\\
        2 years & 0 & 0 & 0 \\
        3 years & 9 & 9 & 0\\
        4 years & 20 & 20 & 0\\
        5 years & 5 & 5 & 0\\
        \hline
        \multicolumn{4}{c}{Stations per variable} \\
        \hline
        Air temperature & 34 & 39 & 71\\
        Rainfall & 34 & 39 & 163\\
        Air humidity & 34 & 39 & 0\\
        Wind direction & 24 & 26 & 0\\
        Wind speed & 25 & 27 & 0\\
        Wind gusts & 25 & 27 & 0\\
        Air pressure & 9 & 11 & 0\\
        Solar radiation & 13 & 15 & 0\\
        Soil temperature & 13 & 13 & 0\\
        Soil humidity & 13 & 13 & 0\\
        Leaf wetness & 23 & 25 & 0 
    \end{tabular}
    \caption{Details of the monitoring networks available  in Campania Region combining measurement stations belonging to both agroclimatic and hydrogeological networks.}
    \label{tab:rarSummary}
    \end{scriptsize}
\end{table}

\begin{figure}
	\centering
	%\includegraphics[scale=.8]{figures/rarLocations}
    \includegraphics[scale=0.6]{figures/map_stations.png}
	\caption{ Geolocation of the stations included in the agrometeorological database of Campania Region, including both agrometeorological and hydrometeorological networks. 
    The stations available are grouped by symbol type and color according to the main sensors available. There are stations having both rain and air temperature sensors or stations having either a rain or an air temperature sensor.}
	\label{fig:rarLocations}
\end{figure}

The monitoring network is in charge of the Agrometereological Regional Centre (CAR, \emph{Centro Agrometereologico Regionale}) under the Department for Agriculture of the Campania Region. The CAR is also in charge of producing pest risk bulletins for the agricultural farms of the Region.

\subsubsection{Hydrogeological risk monitoring network\label{DPCNetwork}}
The hydrogeological risk monitoring network comprises, at the time of this writing, 172 stations within the administrative boundaries of the Campania Region.
Despite the significant number of monitoring points, this network is not especially suitable for agroclimatic-oriented weather monitoring out of the box, since its main purpose is different.
This is reflected in both the geographical distribution of the stations, more focused on areas at high hydrogeological risk rather than cultivated lands, and in their instrumentation.
In fact, apart from thermometers and pluviometers, stations of this network are variously equipped with a range of sensors, most of which are irrelevant to the agrometereological monitoring.
This means that only air temperature and rainfall data are available from this network.

For these reasons, a filtering has been performed prior to the integration in AgriMetSupport.
Only stations deployed at locations deemed of interest, and with suitable equipment, for agrometereological monitoring, have been included in the infrastructure.
Nevertheless, the integration of this network made possible by AgriMetSupport allow to dramatically improve the coverage at least for the two available climatic parameters.

The monitoring network is in charge of the Civil Protection Agency of the Campania Region, which contributes its data under a partnership with the CAR.

\subsection{Retrieve and decode bulletin data}
On hourly basis, CAR and DPC send each a bulletin containing the 10-minute measurements of the last 24 hours.
Each entry of the bulletin represents a point in time and includes the values of all the variables measured by any station.
The two bulletins are sent via sFTP to a server located on the premises of the CRISP\footnote{CRISP is an Interdepartmental Research Centre of the University of Naples Federico II focusing on the \textit{Earth Critical Zone}.}.
%In order to recover for possibly late measurements, on monthly basis a recap bulletin is sent, including all the measurements of the last month, on a 10-minute time scale, with the same format of the hourly bulletin.
%In addition, a reanalysis pipeline runs daily with a time extent of 5 days which can recover bulletins possibly delivered with a time delay.

%Data as received from CAR is not suitable to be inserted into the data base. Each record of the incoming table contains all the measurements of all the climatic variables of all the stations in the RAR; such a record would clearly be poor effective and poor efficient, pointlessly grouping in a single record unrelated data; not to mention that such a record would violate WMO prescriptions about proper handling of climatic data \citep{wcdmp:cdms}.
 
%More importantly, the incoming table labels measurement of the same climatic variable with different names, making any attempt of data analysis impossible. To make things worse, the format of the incoming table is subject to change.
%The most relevant task of the decoding module is to map the different names of the same climatic variable to a standardised attribute, which is also employed by the database.

%\review{(RENDERLO IN MODO PI\'U ACCATTIVANTE: cos\'i sembra una nota di un manuale, evitiamole beghe interne di chi fa cosa, poniamoci come utenti / lettori) For performance reasons, the data insertion is performed with a single SQL INSERT statement per climatic variable. This means that, given the all-or-nothing behaviour of SQL statements, each record to be inserted must be valid, otherwise the whole insertion will fail. It is therefore Weatherprog's responsibility to ensure that all the data submitted to the database can actually be inserted.}
 
%To this end, the decoding module checks whether the data to be inserted is already present, since the insertion of a duplicate record would be rejected by the database. These checks have been optimised in order to avoid an excessive overhead due to database access: each database query is highly time consuming, fairly regardless of the complexity of the query. For this reason, it is highly impractical to check the presence of each value independently, on the contrary more complex queries, with the capability of validating a larger share of the data to be inserted, have been developed.
 
%As said earlier, data is sent from CAR on an hourly basis, containing all the measurements of the previous 24 hours.
To handle the hourly dispatch and provide data to the end users as soon as they are available, the system is configured to automatically have a run of WeatherProg every hour on both CAR and DPC networks, according to the schedule in \cref{Fig:weatherprog:calls}.
This hourly run is responsible for updating the database with the raw data related to the last hour.
Late updates of the incoming data are dealt with by a periodic run of a reanalysis pipeline, on both daily and monthly basis.
%This daily run works on the whole 24-hour incoming table, check which time ranges are missing within the database and fills them.


% The first part of the validation study was performed in the gpu-pedology VM using matlab-vnc instance.
%  - open the VNC client pointing to gpu-pedology
%  - http://192.168.20.10:6080/vnc.html?password=matlab&autoconnect=true&resize=remote
%  - git: search for "perturbation" in tree
%  - folder: run#paper
%  The second part of the validation study was performed on Pedometrics VM (e.g. use of "versions" in .mat files)
%  - folder on Pedometrics VM: /home/giuliano/work/Projects/URCOFI/run#paper/TABLES/
\subsection{Validation of quality control and gap-filling procedures} \label{sec:QcheckValidation}
AgriMetSupport enables the management of agrometeorological data using fully automated or semi-automated procedures. % which belongs above all to the WeatherProg engine.
A user of AgriMetSupport should always be aware of the level of confidence and reliability associated with the use of each internal component, with particular emphasis here on WeatherProg and its constituent modules as they were shown in \cref{sec:weatherprog}. 
To achieve this objective, WeatherProg was equipped with a smart deviation from its standard run.
In other words, it was equipped with a switch capable to introduce random noise in the raw data and then measure its own performance in fixing them. % known anomalous data.
Random noise is generated on-the-fly in the run, also with reproducibility, and it is never stored in the database.

A validation study was carried out for the scope of this article on 10-minute air temperature data, in the year 2021, for both RAR and DPC networks, in both quality control and infill modules.
The deviation or switch was introduced in the 10-minutes pipeline tackling the daily run dedicated to the creation of no-gap and certified data, as depicted in \cref{Fig:weatherprog:calls} .%\note{(MODIFY THE FIGURE TO ADD THE DEVIATION/SWITCH GRAPHICALLY))}.
The insert of noise simulates what could actually happen if receiving true anomalous data but forcing perturbed signals to overstress the WeatherProg modules.
If the perturbation switch is active, noisy data are created according to different levels of absolute amplitude ($A$) and quota ($Q$), where amplitude is a magnitude exaggeration factor applied to air temperature (in this validation study $A$ is set to its maximum, that is, $A=10$) while quota accounts for the relative amount of raw measurements into which noise is inserted ($Q=30\%$ in this validation study).
The following procedure was repeated for each of the 30 randomly selected days within the year 2021, where each day has $N_{rec}=12816$ records (i.e., 144 10-minutes records $\times$ 89 stations):

\begin{enumerate}
    \item get the number of $N$ records to which add noise, $N = int( N_{rec} * Q ) = int(12816 \times 30 / 100) = 3845$;
    \item get the vector $P_{idx}$ of $N$ random row indexes out of $N_{rec}$ daily raw records stored in the data frame $RawData[\,N_{rec}\,,\,Air \; Temperature\,]$;
    \item get the sign vector $S_{(\pm)}$ of length $N$ made by a random sequence of $+$ and $-$ signs (i.e. a sequence of $+1$ and $-1$);
    \item generate a vector $R_{abs}$ of absolute random numbers of length $N$ from a uniform [0,1] distribution;
    \item put $N$ noisy values in the data frame $RawData$ at $P_{idx}$ random row indexes as follows:
    %$$
    \begin{multline}
    RawData[\,P_{idx}\,,\,Air \; Temperature\,] = \\
    RawData[\,P_{idx}\,,\,Air \; Temperature\,] + S_{(\pm)} \times R_{abs} \times A      
    \end{multline}
    %$$
\end{enumerate}

%according to the different modules (qcheck, infill, tscale aggregation) including a manual implementation of a geostatistical analysis (variogram + kriging with err.var). I evaluate the propagation of uncertainty in other calculations using agrometeo data, such as bioclimatic indices or simulation models, such as plasmorossi using hourly data.
% Finally, I collect all the errors made in comparison with the original non-perturbed data, such as:
% [on 10-min data]
%   > N of data not passig qcheck but good; (false negative, FN)
%   > N of data passing qcheck but bad;     (false positive, FP)
%   > rmse on meas vs pert data FN & FP;    (rmse on FN & FP)
%   > rmse on infilled vs measured data;    (skip)
% [on h1 data, after h1 qcheck + infill]
%   > develop a procedure to validate WeatherProg processing with
%     plasmorossi.
% [on h24 data, after h24 qcheck + infill]
%   > N of data not passig qcheck but good;
%   > N of data passing qcheck but bad;
%   > rmse on infilled vs measured data;
%   > GDD;
%   > kriging variance error.
% [on h24 data, aggregated without 10-min qcheck + infill]
%   > same as previous block
% Finally, I have to compare data at h1 / h24 before / after data curation: it means that I should calculate the statitistcs or run models also on data without qcheck + infill to compare with the situation in which I use weatherprog for data curation (qcheck + infill) and get a quantitative mesurement of the usefulness of WeatherProg.

%We can think to a WeatherProg module as a black box to which agrometeorological data is passed as input and additional information (metadata) is attached to the original raw data, such as flags concerning the quality check procedure or infilled values which are predicted values substituting the raw ones because of their poor reliability.
%This knowledge was used to enhance results coming from WeatherProg with particular reference to the quality check module and the gaps infilling module.



% The second part of the validation study was performed on Pedometrics VM (e.g. use of "versions" in .mat files)
%  - folder on Pedometrics VM: /home/giuliano/work/Projects/URCOFI/run#paper/TABLES/
% Use the previous folder to analyse results.
\section{Results and Discussion}[Giuliano][wip]
AgriMetSupport exemplifies a model GCI that can be seamlessly customised to manage meteorological networks across several territories.
Its design underscores pronounced multi-level granularity,
particularly evident in the flexibility afforded by its containerized deployment architecture. 
This granularity enables the distribution of its stack across the internet, for instance, allowing the data tier and the presentation tier to operate from distinct geographical locations. 
Moreover, the capacity to instantiate separate Docker containers for production pipelines (\cref{Fig:weatherprog:calls}) and testing or debugging purposes facilitates a robust development lifecycle.
Distinct databases for development and production -- associated to two different WeatherProg instances -- further enhance this segregation, ensuring that data integrity and application stability are maintained.

At a physical level, AgriMetSupport's granularity allows for the integration and management of disparate monitoring networks within a unified infrastructure.
This capability was demonstrated in the Campania Region case study, which showed the integration of CAR and DCP networks.
Furthermore, the system's architecture supports the incorporation of smart and low-cost stations, satisfying the requirements of precision agriculture and advanced Internet of Things (IoT) applications. %, albeit these applications were not explored in the case study for brevity.

\begin{figure}
	\centering
	\includegraphics[scale=.30]{figures/Fig_qck_versions.tif}
	\caption{ Two panels: 
    (a) evolution performance of the quality control procedure on air temperature;
    \review{(b) performance of the infill procedure}.
    Details about versions: version 1 uses a preliminary version of range, persistence and continuity control types; version 2 adds spatial control type to version 1; version 3 introduces enhancements to the continuity and spatial control types while reducing the amount of dubious outcomes; version 4 shows overall enhancements given by a smarter quality control logic, as reported in \cref{tab:qcheck_m10_airT}.
    Details about legend. TN: true negative; TP: true positive; FN: false negative; FP: false positive; DU: dubious; UU: undecided or unprocessed. }
	\label{fig:perturbationCharts}
\end{figure}

%The schedule of pipelines execution depicted in \cref{Fig:weatherprog:calls} is a clear evidence of a further level of granularity available within WeatherProg, which is the backbone engine of the whole cyber-physical system.
WeatherProg, serving as the backbone engine of AgriMetSupport, facilitates a detailed and user-friendly management of standard, reanalysis, or recursive pipelines, as clearly highlighted in the schedule shown in \cref{Fig:weatherprog:calls}.
This includes the activation of specific modules such as data decoding, quality control, and data infilling, tailored to particular monitoring networks, agrometeorological variables, and time scales.

The validation study performed on WeatherProg's quality control and data infilling modules (\cref{fig:perturbationCharts}) illustrates the system's adeptness at processing and refining meteorological data.
Using artificially perturbed data -- as explained in the noisy data generation given in \cref{sec:QcheckValidation} -- in place of raw measurements from Regional bulletins allowed for a direct comparison of WeatherProg's capabilities in anomaly detection and data correction against the raw, original, and unaltered observations.

As delineated in the quality control logic of WeatherProg (\cref{sec:qcheck}), the system is designed to minimize the probability of getting dubious flags, thereby reducing data ambiguity. 
Ambiguity is reduced since a dubious singleton cannot be neither used nor discarded until either new evidence in WeatherProg logic or a human sets it as correct or wrong.
This strategic approach ensures a higher precision in anomaly detection, as evidenced by the minimal increase in mismatched outcomes (both false negatives and false positives) compared to a significant rise in accurately processed data points (both true positives and true negatives) when passing from version 1 to version 4 of the quality control module.
Figure \cref{fig:perturbationCharts} delineates the evolutionary trajectory of WeatherProg's quality control mechanisms, showcasing enhancements driven by iterative feedback from the validation studies. These iterations involved the introduction of random noise to raw measurements, simulating real-world data anomalies. The evolution from version 1 through version 4 illustrates progressive refinements in anomaly detection, which can also expand with the availability of larger datasets.

\begin{table}[]
\centering
\begin{scriptsize}
    \begin{tabular}{cccccc}
        \toprule
        Perturbed (True/False) & Outcome & Continuity & Spatial & (Count) & Percent (\%) \\
        \midrule
        0 & C  & C  & AM & 90   & 0.719  \\
        0 & C  & C  & AU & 309  & 2.468  \\
        0 & C  & C  & C  & 836  & 6.676  \\
        0 & C  & C  & D  & 7345 & 58.657 \\
        0 & D  & D  & AM & 2    & 0.016  \\
        0 & D  & D  & AU & 6    & 0.048  \\
        0 & D  & D  & D  & 115  & 0.918  \\
        0 & UP & AM & UC & 3    & 0.024  \\
        0 & W  & D  & W  & 13   & 0.104  \\
        0 & W  & W  & AM & 8    & 0.064  \\
        0 & W  & W  & AU & 1    & 0.008  \\
        0 & W  & W  & D  & 32   & 0.256  \\
        0 & W  & W  & W  & 4    & 0.032  \\
        1 & C  & C  & AM & 10   & 0.080  \\
        1 & C  & C  & AU & 24   & 0.192  \\
        1 & C  & C  & C  & 87   & 0.695  \\
        1 & C  & C  & D  & 628  & 5.015  \\
        1 & D  & D  & AM & 2    & 0.016  \\
        1 & D  & D  & AU & 14   & 0.112  \\
        1 & D  & D  & D  & 296  & 2.364  \\
        1 & W  & D  & W  & 32   & 0.256  \\
        1 & W  & W  & AM & 32   & 0.256  \\
        1 & W  & W  & AU & 88   & 0.703  \\
        1 & W  & W  & D  & 2248 & 17.952 \\
        1 & W  & W  & W  & 297  & 2.372  \\
        \bottomrule
    \end{tabular}
\end{scriptsize}
\caption{Summary of quality check performance on perturbed data. For brevity, the peristence quality control is omitted. (I have to remove the column Count since it refers to one day only, while percentages are a good picture of the overall performance).}
\label{tab:validation_outcomes}
\end{table}

%In \cref{fig:perturbationCharts} it is shown the evolution of the quality control thanks to the feedback received by the results of validation study based on the introduction of random noise in raw measurements.\\
%add: (1) rmse on qcheck; (2) rmse on infilled data\\
%add some results of the perturbation study:\\
% - percentage of noise and statistics about the goodness of the quality check in detecting noisy data: TN, TP, FN, FP\\
% - discuss the improvement over versions (1,2,3,4)
% - show the temperature values and statistics that belong to the FP group which is the major error present in version 4 (this to demonstrate that noise is very low and this was the main reason why the qcheck module did not detect them)\\
% - 
Correct outcomes are made by both true positives (non perturbed data with a correct outcomes) which account for 68.52 \% of the data and true negatives (perturbed data with a wrong outcomes) which account for 21.54 \% of the data. Overall, the quality check module returns a total of 90.06 \% of correct outcomes out of the data processed during validation (\cref{tab:validation_outcomes}).
Wrong outcomes are made by both false negatives (non perturbed data with a wrong outcome) which account for 0.46 \% of the data and false positives (perturbed data with a correct outcome) which account for 5.98 \% of the data. Overall, the quality control module returns a total of 6.45 \% of wrong outcomes. Limiting the analysis to false positives, the distribution of the random noise added to raw measurements shows that about 45 \% is in the range $[0,\; \pm1]$ and about 47 \% is in range $]\pm1,\; \pm2]$. This finding confirms that the quasi totality of perturbed data are incorrectly flagged as correct only because of the slight deviation from the raw original value.
Only 0.73 \% of the quality control outcomes are wrong (both in false positives and in false negatives) because all modules were wrong, while in the majority of the other cases the spatial module was dubious and the persistence module had unreliable auxiliary data. This situation arises since a high volume of data was forced with noise, while in standard operational conditions these outcomes are highly reduced and therefore a higher performance of the quality control module is expected.
The remaining 3.47 \% of outcomes are dubious and the majority of them (2.49 \%) are perturbed data. This highlights again the expectation of a good performance in identifying possible anomalous data in operational contexts.
The validation study shown in \cref{tab:validation_outcomes} highlights an impressive efficiency of WeatherProg's quality control, with a high percentage of well-fitted outcomes demonstrating the system's precision in handling agrometeorological data. High percentages of well-fitted outcomes versus low percentages of mismatches are pivotal to assess / state that a significant majority of data points were accurately processed. This indicates a robust anomaly detection capability within WeatherProg, essential for reliable agrometeorological analysis.

\note{add here the evaluation of the infill procedure.}

\section{Conclusions}
This study has demonstrated the versatility and efficacy of AgriMetSupport, a Geospatial Cyber-Infrastructure (GCI), in managing and optimizing agrometeorological networks within the Campania Region.
The case study not only highlights the system's capacity for scaling across territories and networks but also emphasizes its potential in enhancing the %granularity and 
accessibility of meteorological data for a wide range of applications.

AgriMetSupport has proven crucial 
for territorial agencies, research pro-jects and private companies attempting
to leverage technological advancements and improve the support provided to farmers and stakeholders. 
By bridging the gap between raw agrometeorological observations and the need for high-quality, accessible data, AgriMetSupport simplifies the operational complexities associated with data management and service implementation. 
This simplification is critical in today's agricultural landscape, where the demands for precision and efficiency are ever-increasing.

Furthermore, the system's openness and interoperability facilitate the integration of diverse data sources, ensuring a comprehensive and inclusive approach to agrometeorological monitoring. This aspect is particularly relevant in the context of European Union regulations and the broader imperative for sustainable agricultural practices. AgriMetSupport's capability to support essential services - from crop simulation and irrigation management to pest risk management and civil protection - illustrates its role as a cornerstone technology for modern agriculture.

The deployment of low-cost monitoring stations, as explored in this study, offers a promising avenue for expanding network coverage and enhancing data accuracy.
However, the evaluation of these stations' suitability for various applications warrants further investigation.
Future research should focus on assessing the performance of these stations in quality control, data reconstruction, and their effectiveness in supporting decision-making processes for environmental and farm management.

In conclusion, AgriMetSupport embodies a significant step forward in the search for a more integrated, efficient, and user-friendly approach to agrometeorological monitoring.
Its development and implementation pave the way for enhanced agricultural productivity, environmental management, and the well-being of farming communities. % across the globe.

%Even though the case study is routed on the management of physical networks in Campania Region, there is huge potential in deploy AgriMetSupport scaling of territory, number of both networks and stations

%\note{[COPIED]}(**) The importance of tools like the GCI / WeatherProg engine that can provide a support for agencies constrained to adopt such technological advancements/improvements to raise the quality of the delivered support they can offer to farmers and stakeholders.

%\note{[COPIED]} There is an evident gap between raw agrometeorological observations made by sensors in gauges in a monitoring network and the necessity to provide public access to data of good quality in the form of multipoint time series or of a temporal stack of digital maps.

%\note{[COPIED]} WeatherProg is able to fill this gap and to simplify(stress this concept, i.e. that WeatherProg simplifies al operations!!!!) the implementation of services (that are mandatory!) necessary to support agriculture for todays threatens and to coadiuvate decision making in environmental management. It includes the state of the art of methods embedded in the main modules of the program.

%\note{Openness of AgriMetSupport [to receive data from any source (see \citep{SAWANT_2017})] of being interoperable with systems and platform implementing  standards for sensor data and metadata in order to process measurements within the AgriMetSupport framework.}



\section*{Future Perspectives}
In addition to the demonstrated capabilities and potential future directions previously outlined, AgriMetSupport is ready to play a role in the ongoing Italian Agritech project. 
This initiative represents a breakthrough in agricultural technology, focusing on the precision management of agricultural pests through advanced simulation models.

Central to its contribution to the Agritech project, AgriMetSupport's ability in generating high-resolution raster maps of critical agrometeorological variables is significantly enhanced through the essential use of quality-controlled data.
This critical integration ensures that the geospatial representations of climate data are not only detailed but also reliable and accurate. 
By leveraging data that have undergone rigorous quality control, as detailed in the results of this study, AgriMetSupport can substantially improve the accuracy and effectiveness of pest simulation models. 
This synergy between quality control and advanced mapping capabilities highlights the system's versatility and underscores its potential to significantly advance sustainable agriculture practices.

The involvement in the Agritech project not only highlights the ongoing relevance of AgriMetSupport but also its capacity to adapt and respond to the evolving needs of the agricultural sector. 
As we look to the future, AgriMetSupport's integration into projects like Agritech exemplifies its role as a key technological asset, ready to tackle some of the most pressing challenges in agricultural and environmental management.

\section*{Acknowledgements}
\subsection*{Funding}
%This work was supported firstly by the SOILCONS-WEB project (LIFE08 ENV/IT/000408) and secondly by the Phitosanitary Service (UOD21) of the Directorate General for Agricultural, Food and Forest Policies of the Campania Region (DG7), within the URCoFi Executive Plan (2016-2022).
The groundwork for this research was significantly supported by funding from two sources. 
The initial phase was underpinned by the SOILCONS-WEB project (LIFE08 ENV/IT/000408), an initiative aimed at promoting soil conservation and the adoption of sustainable land management practices. 
It was during this foundational phase that I had the opportunity to develop the WeatherProg core engine, an endeavor that not only aligned with but also significantly contributed to the SOILCONS-WEB project's objectives of advancing environmental sustainability through technological innovation.

Subsequent support from the Phytosanitary Service (UOD21) of the Directorate General for Agricultural, Food and Forest Policies of the Campania Region (DG7), within the URCoFi Executive Plan (2016-2022), further facilitated the refinement and expansion of the WeatherProg engine, including the integration of smart stations and the development of web services, to address contemporary agricultural challenges.

These funding sources underscore the collaborative and multidisciplinary nature of our research, reflecting a wide commitment to enhancing agricultural technologies and practices.% in the Campania Region.


%% The Appendices part is started with the command \appendix;
%% appendix sections are then done as normal sections

%\appendix


%% \section{}
%% \label{}

%% If you have bibdatabase file and want bibtex to generate the
%% bibitems, please use
%%
%\bibliographystyle{elsarticle-harv} 
\bibliography{biblio-items.bib}

%% else use the following coding to input the bibitems directly in the
%% TeX file.

%% \begin{thebibliography}{00}

%% \bibitem[Author(year)]{label}
%% Text of bibliographic item

%% \end{thebibliography}



\end{document}

\endinput
%%
%% End of file `elsarticle-template-harv.tex'.
